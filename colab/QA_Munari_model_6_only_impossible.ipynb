{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QA_Munari_model_6_only_impossible.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhB1txNs--qG"
      },
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "proj_dir = \"/content/drive/MyDrive/QA_project\" #Change to directory where there are the train and dev set and glove embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_RLXkU5pQib"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/QA_project/glove.6B.zip\" -d \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OXkY6uNDA7u"
      },
      "source": [
        "with open('/content/drive/MyDrive/QA_project/train-v2.0.json') as f:\n",
        "  train = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/QA_project/dev-v2.0.json') as f:\n",
        "  dev = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBgcqTz9jw5I"
      },
      "source": [
        "# Load train data\n",
        "train_contexts = []\n",
        "train_questions = []\n",
        "train_questions_id = [] #used for evaluation script\n",
        "train_is_imp = []\n",
        "train_answers = []\n",
        "train_answers_start = []\n",
        "train_answers_end = []\n",
        "train_index = []\n",
        "\n",
        "i = 0\n",
        "\n",
        "for data in train['data']:\n",
        "  title = data['title']\n",
        "\n",
        "  for paragraph in data['paragraphs']:\n",
        "    context = paragraph['context']\n",
        "\n",
        "    for qa in paragraph['qas']:\n",
        "      question = qa['question']\n",
        "      id = qa['id']\n",
        "      is_impossible = qa['is_impossible']\n",
        "\n",
        "      if is_impossible:\n",
        "        train_is_imp.append(1)\n",
        "        train_contexts.append(context)\n",
        "        train_questions.append(question)\n",
        "        train_answers.append(\"\")\n",
        "        train_answers_start.append(0)\n",
        "        train_answers_end.append(0)\n",
        "        train_index.append(i)\n",
        "        i+=1\n",
        "      else:\n",
        "        for answer in qa['answers']:\n",
        "          text = answer['text']\n",
        "          start = answer['answer_start']\n",
        "          \n",
        "          train_is_imp.append(0)\n",
        "          train_contexts.append(context)\n",
        "          train_questions.append(question)\n",
        "          train_questions_id.append(id)\n",
        "          train_answers.append(text)\n",
        "          train_answers_start.append(start)\n",
        "          train_answers_end.append(start + len(text))\n",
        "          train_index.append(i)\n",
        "          i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXZCyXQQENl3"
      },
      "source": [
        "# Load dev data\n",
        "dev_contexts = []\n",
        "dev_questions = []\n",
        "dev_questions_id = [] #used for evaluation script\n",
        "dev_is_imp = []\n",
        "dev_answers = []\n",
        "dev_answers_start = []\n",
        "dev_answers_end = []\n",
        "\n",
        "for data in dev['data']:\n",
        "  title = data['title']\n",
        "\n",
        "  for paragraph in data['paragraphs']:\n",
        "    context = paragraph['context']\n",
        "\n",
        "    for qas in paragraph['qas']:\n",
        "      question = qas['question']\n",
        "      id = qas['id']\n",
        "      is_impossible = qas['is_impossible']\n",
        "\n",
        "      if is_impossible:\n",
        "        dev_is_imp.append(1)\n",
        "        dev_contexts.append(context)\n",
        "        dev_questions.append(question)\n",
        "        dev_questions_id.append(id)\n",
        "        dev_answers.append(\"\")\n",
        "        dev_answers_start.append(0)\n",
        "        dev_answers_end.append(0)\n",
        "      else:\n",
        "        for answer in qas['answers']:\n",
        "          text = answer['text']\n",
        "          start = answer['answer_start']\n",
        "\n",
        "          dev_is_imp.append(0)\n",
        "          dev_contexts.append(context)\n",
        "          dev_questions.append(question)\n",
        "          dev_questions_id.append(id)\n",
        "          dev_answers.append(text)\n",
        "          dev_answers_start.append(start)\n",
        "          dev_answers_end.append(start + len(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B70ZUumVe2TT"
      },
      "source": [
        "# Tokenizer\n",
        "from nltk.tokenize.regexp import RegexpTokenizer\n",
        "\n",
        "tkn = RegexpTokenizer('[\\s!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\nâ€”]', gaps=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCYxQNIajSZJ"
      },
      "source": [
        "# Tokenize training set and build vocabulary\n",
        "vocab = set()\n",
        "\n",
        "tokenized_train_contexts = tkn.tokenize_sents(map(lambda x:x.lower(),train_contexts))\n",
        "span_train_contexts = list(tkn.span_tokenize_sents(map(lambda x:x.lower(),train_contexts)))\n",
        "\n",
        "tokenized_train_questions = tkn.tokenize_sents(map(lambda x:x.lower(),train_questions))\n",
        "\n",
        "for item in tokenized_train_contexts:\n",
        "  vocab.update(item)\n",
        "\n",
        "for item in tokenized_train_questions:\n",
        "  vocab.update(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uQRZu51V-xD"
      },
      "source": [
        "# Tokenize dev set\n",
        "tokenized_dev_contexts = tkn.tokenize_sents(map(lambda x:x.lower(),dev_contexts))\n",
        "span_dev_contexts = list(tkn.span_tokenize_sents(map(lambda x:x.lower(),dev_contexts)))\n",
        "\n",
        "tokenized_dev_questions = tkn.tokenize_sents(map(lambda x:x.lower(),dev_questions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEz3lgllM7em"
      },
      "source": [
        "# Build word index\n",
        "word_index = {}\n",
        "for idx, voc in enumerate(vocab):\n",
        "  word_index[voc] = idx + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oxuKGwzO4b_"
      },
      "source": [
        "# Build token-answer correspondence training\n",
        "train_start = []\n",
        "train_end = []\n",
        "\n",
        "for answ_start, answ_end, span_context, is_imp in zip(train_answers_start, train_answers_end, span_train_contexts, train_is_imp):\n",
        "  if is_imp == 1:\n",
        "    train_start.append([0]*len(span_context))\n",
        "    train_end.append([0]*len(span_context))\n",
        "  else:\n",
        "    answer_enc = []\n",
        "    answer_start_enc = []\n",
        "    answer_end_enc = [0]*len(span_context)\n",
        "\n",
        "    started = False\n",
        "    end_idx = None\n",
        "\n",
        "    for idx, span in enumerate(span_context):\n",
        "      if span[0] >= answ_start and not started:\n",
        "        answer_start_enc.append(1)\n",
        "        answer_enc.append(1)\n",
        "        started = True\n",
        "        end_idx = idx\n",
        "      elif started and span[1] <= answ_end:\n",
        "        end_idx = idx\n",
        "        answer_start_enc.append(0)\n",
        "        answer_enc.append(1)\n",
        "      else:\n",
        "        answer_start_enc.append(0)\n",
        "        answer_enc.append(0)\n",
        "\n",
        "    if end_idx:\n",
        "      answer_end_enc[end_idx] = 1\n",
        "\n",
        "    train_start.append(answer_start_enc)\n",
        "    train_end.append(answer_end_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tELUl0xWRUG"
      },
      "source": [
        "# Build token-answer correspondence dev\n",
        "dev_start = []\n",
        "dev_end = []\n",
        "\n",
        "for answ_start, answ_end, span_context, is_imp in zip(dev_answers_start, dev_answers_end, span_dev_contexts, dev_is_imp):\n",
        "  if is_imp == 1:\n",
        "    dev_start.append([0]*len(span_context))\n",
        "    dev_end.append([0]*len(span_context))\n",
        "  else:\n",
        "    answer_enc = []\n",
        "    answer_start_enc = []\n",
        "    answer_end_enc = [0]*len(span_context)\n",
        "\n",
        "    started = False\n",
        "    end_idx = None\n",
        "\n",
        "    for idx, span in enumerate(span_context):\n",
        "      if span[0] >= answ_start and not started:\n",
        "        answer_start_enc.append(1)\n",
        "        answer_enc.append(1)\n",
        "        started = True\n",
        "        end_idx = idx\n",
        "      elif started and span[1] <= answ_end:\n",
        "        end_idx = idx\n",
        "        answer_start_enc.append(0)\n",
        "        answer_enc.append(1)\n",
        "      else:\n",
        "        answer_start_enc.append(0)\n",
        "        answer_enc.append(0)\n",
        "\n",
        "    if end_idx:\n",
        "      answer_end_enc[end_idx] = 1\n",
        "\n",
        "    dev_start.append(answer_start_enc)\n",
        "    dev_end.append(answer_end_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-p5L4t1oMn"
      },
      "source": [
        "del span_train_contexts\n",
        "del span_dev_contexts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQFlSKhXBz6"
      },
      "source": [
        "def tokenized_texts_to_sequences(tkn_texts, word_index):\n",
        "  sequences = []\n",
        "  for text in tkn_texts:\n",
        "    seq = []\n",
        "    for word in text:\n",
        "      seq.append(word_index[word]) if word in word_index.keys() else seq.append(1)\n",
        "    sequences.append(seq)\n",
        "  \n",
        "  return sequences\n",
        "\n",
        "# Integer encoding training\n",
        "train_ctx = tokenized_texts_to_sequences(tokenized_train_contexts, word_index)\n",
        "train_q = tokenized_texts_to_sequences(tokenized_train_questions, word_index)\n",
        "\n",
        "# Integer encoding dev\n",
        "dev_ctx = tokenized_texts_to_sequences(tokenized_dev_contexts, word_index)\n",
        "dev_q = tokenized_texts_to_sequences(tokenized_dev_questions, word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mB-hhWwbK0a"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad train sequences and answer encoding\n",
        "train_ctx = pad_sequences(train_ctx, padding='post')\n",
        "train_q = pad_sequences(train_q, padding='post')\n",
        "train_start = pad_sequences(train_start, padding='post')\n",
        "train_end = pad_sequences(train_end, padding='post')\n",
        "\n",
        "# Pad dev sequences\n",
        "dev_ctx = pad_sequences(dev_ctx, padding='post')\n",
        "dev_q = pad_sequences(dev_q, padding='post')\n",
        "dev_start = pad_sequences(dev_start, padding='post')\n",
        "dev_end = pad_sequences(dev_end, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy74ktABbfrZ"
      },
      "source": [
        "# Save target list to numpy array\n",
        "train_is_imp_arr = np.array(train_is_imp)\n",
        "\n",
        "dev_is_imp_arr = np.array(dev_is_imp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJP0ara6kl-D"
      },
      "source": [
        "# shuffle train data\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "shuffler = np.random.permutation(train_ctx.shape[0])\n",
        "train_ctx_shuffled = train_ctx[shuffler]\n",
        "train_q_shuffled = train_q[shuffler]\n",
        "train_start_shuffled = train_start[shuffler]\n",
        "train_end_shuffled = train_end[shuffler]\n",
        "train_imp_shuffled = train_is_imp_arr[shuffler]\n",
        "\n",
        "train_index = np.array(train_index)\n",
        "train_index_shuffled = train_index[shuffler]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOTpgwmGpyWU"
      },
      "source": [
        "# Preparing embedding\n",
        "embeddings_index = {}\n",
        "with open('/content/glove.6B.300d.txt') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.array(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAtgwh2qnLK"
      },
      "source": [
        "# Define embedding matrix\n",
        "embedding_matrix = np.zeros((len(word_index) + 2, 300))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCxf-ZS8V2-B"
      },
      "source": [
        "num_words = len(word_index) + 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMMsLljAkdI5"
      },
      "source": [
        "MODEL DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1wXO67XcQg0"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYB_lIkkrTfm"
      },
      "source": [
        "class RepeatConcat(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(RepeatConcat, self).__init__()\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    if mask:\n",
        "      return mask[0]\n",
        "    return mask\n",
        "\n",
        "  def call(self, inputs, training, mask=None):\n",
        "    ctx = inputs[0]\n",
        "    q = inputs[1]\n",
        "\n",
        "    q_repeated = K.tile(q, [1,K.shape(ctx)[1],1])\n",
        "\n",
        "    return K.concatenate([q_repeated, ctx], axis=-1)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "      \n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sAVSZy9gin_"
      },
      "source": [
        "class Query2Context(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(Query2Context,self).__init__()\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    if mask:\n",
        "      return mask[0]\n",
        "    return mask\n",
        "\n",
        "  def call(self, inputs, training, mask=None):\n",
        "    ctx = inputs[0]\n",
        "    q = inputs[1]\n",
        "    q_mask = mask[0] if mask else None\n",
        "\n",
        "    scores = tf.matmul(ctx, q, transpose_b=True)\n",
        "    max = tf.math.reduce_max(scores, axis=-1)\n",
        "    if q_mask is not None:\n",
        "      padding_mask = tf.logical_not(q_mask)\n",
        "      # Bias so padding positions do not contribute to attention distribution.\n",
        "      # Note 65504. is the max float16 value.\n",
        "      if scores.dtype is tf.float16:\n",
        "        max -= 65504. * tf.cast(padding_mask, dtype=scores.dtype)\n",
        "      else:\n",
        "        max -= 1.e9 * tf.cast(padding_mask, dtype=scores.dtype)\n",
        "\n",
        "    soft = tf.nn.softmax(max, axis=-1)\n",
        "    soft = tf.expand_dims(soft, -2)\n",
        "    result = tf.matmul(soft, ctx)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    return config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42PgDKQBcTHh"
      },
      "source": [
        "# define input layers\n",
        "question_input = keras.Input(shape=(None,), name=\"question\")\n",
        "context_input = keras.Input(shape=(None,), name=\"context\")\n",
        "\n",
        "# embedding\n",
        "token_emb = Embedding(num_words, 300, weights=[embedding_matrix], trainable=False, mask_zero=True)\n",
        "q_emb = token_emb(question_input)\n",
        "q_emb = Dropout(0.4)(q_emb)\n",
        "c_emb = token_emb(context_input)\n",
        "c_emb = Dropout(0.4)(c_emb)\n",
        "\n",
        "# encoder\n",
        "q_encoding = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.1))(q_emb)\n",
        "c_encoding = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.1))(c_emb)\n",
        "\n",
        "# combination\n",
        "\n",
        "c2q, scores = Attention()([c_encoding, q_encoding], return_attention_scores=True)\n",
        "q2c = Query2Context()([c_encoding, q_encoding])\n",
        "concat = Concatenate(axis=-1)([c_encoding, c2q])\n",
        "concat = RepeatConcat()([concat,q2c])\n",
        "\n",
        "# decoding\n",
        "decoding1 = Bidirectional(GRU(units=64, return_sequences=True, dropout=0.1))(concat)\n",
        "imp_predictor = Bidirectional(GRU(units=64, dropout=0.1))(decoding1)\n",
        "imp_predictor = Dense(100, activation='relu')(imp_predictor)\n",
        "imp_predictor = Dropout(0.1)(imp_predictor)\n",
        "imp_predictor = Dense(20, activation='relu')(imp_predictor)\n",
        "imp_predictor = Dropout(0.1)(imp_predictor)\n",
        "imp_predictor = Dense(1, activation='sigmoid', name=\"is_impossible\")(imp_predictor)\n",
        "\n",
        "model = keras.Model(\n",
        "    outputs=[imp_predictor]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjP89oEkcFL_"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss={\"is_impossible\": keras.losses.BinaryCrossentropy()\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRUCQi4Irqaa"
      },
      "source": [
        "keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BG_cEnplmYx"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O_65ziZjqs1"
      },
      "source": [
        "# apply early stopping\n",
        "import time \n",
        "\n",
        "logdir = os.path.join(os.curdir, \"logs\", \"run_{}\".format(time.time()))\n",
        "\n",
        "callbacks = [keras.callbacks.TensorBoard(logdir),\n",
        "             keras.callbacks.EarlyStopping(patience=5),\n",
        "             keras.callbacks.ModelCheckpoint(\"qa_attention_model.h5\",save_best_only=True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dr2g6Jsf7Qs"
      },
      "source": [
        "history = model.fit(x={\"context\": train_ctx_shuffled, \"question\": train_q_shuffled},\n",
        "                   y={\"is_impossible\": train_imp_shuffled},\n",
        "                   epochs=30,\n",
        "                   batch_size=512,\n",
        "                   validation_split=0.2,\n",
        "                   callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSCVU1dZVxQ"
      },
      "source": [
        "prediction = model.predict([dev_q, dev_ctx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIJ-Fm5Mv_JL"
      },
      "source": [
        "np.save('/content/drive/MyDrive/QA_project/is_imp.npy', prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrFZdfozqwvC"
      },
      "source": [
        "# USE MODEL 5 TO PREDICT AFTER FILTERING"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}